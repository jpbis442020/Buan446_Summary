{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90e0d72-7e4b-48fb-8c62-825e4cd921bf",
   "metadata": {},
   "source": [
    "# Week 5 Problem Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dfd602-8c85-4e88-841b-351f487b7fe5",
   "metadata": {},
   "source": [
    "Each week you will have a problem set due on Sunday night before midnight.\n",
    "You will download a template Jupyter notebook file (like this one) and complete all of your work in the file then save it with your last name in the following format:\n",
    "lastname_week5ProblemSet.ipynb for example I would submit Zematis_week5ProblemSet.ipynb  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f091b-7e14-4447-bd82-c6f7ddf6e06c",
   "metadata": {},
   "source": [
    "Deitel Exercise 8.10\n",
    "Deitel Exercise 8.16\n",
    "Deitel Exercise 8.22\n",
    "Deitel Exercise 9.3 \n",
    "Deitel Exercise 9.4\n",
    "Deitel Exercise 9.16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb595e6-fda9-4d03-8b44-b71ecfbdf39f",
   "metadata": {},
   "source": [
    "1. Search online for lists of positive sentiment words and negative sentiment words. Create a script that inputs text, then determines if that text is positive or negative based on the total number of positive or negative words. Test it out on text you find online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04901527-6d6e-4e18-ac6e-598082751ca4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 18,
    "lastExecutedAt": 1690633204721,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# List of positive sentiment words\npositive_words = [\"happy\", \"joyful\", \"excited\", \"amazing\", \"awesome\", \"fantastic\", \"great\", \"love\", \"wonderful\", \"excellent\", \"delighted\", \"blissful\", \"pleased\", \"content\", \"grateful\", \"thrilled\", \"satisfied\", \"ecstatic\", \"glad\", \"upbeat\"]\n\n# List of negative sentiment words\nnegative_words = [\"sad\", \"angry\", \"frustrated\", \"disappointed\", \"terrible\", \"awful\", \"horrible\", \"bad\", \"hate\", \"unpleasant\", \"miserable\", \"depressed\", \"upset\", \"regretful\", \"dreadful\", \"distressed\", \"angry\", \"annoyed\", \"disgusted\", \"irritated\"]\n\ndef sentiment_analysis(text):\n    positive_count = 0\n    negative_count = 0\n    \n    # Convert the text to lowercase for case-insensitive matching\n    text = text.lower()\n    \n    # Split the text into individual words\n    words = text.split()\n    \n    # Count the number of positive and negative words\n    for word in words:\n        if word in positive_words:\n            positive_count += 1\n        elif word in negative_words:\n            negative_count += 1\n    \n    # Determine the sentiment based on the counts\n    if positive_count > negative_count:\n        sentiment = \"Positive\"\n    elif positive_count < negative_count:\n        sentiment = \"Negative\"\n    else:\n        sentiment = \"Neutral\"\n    \n    return sentiment\n\n# Example usage\ntext = 'Under trickle-down economics, it didn’t matter where companies made things as long as it helped their bottom line.Were changing that – starting with over half a trillion dollars of private investment in American manufacturing and industries of the future.'\nresult = sentiment_analysis(text)\nresult",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text:  good good bad joy love hate awful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Code for Problem 1\n",
    "positive_words = [\"happy\", \"joy\", \"love\", \"awesome\", \"amazing\"]\n",
    "negative_words = [\"sad\", \"angry\", \"hate\", \"terrible\", \"awful\"]\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    positive_count = sum(word in positive_words for word in words)\n",
    "    negative_count = sum(word in negative_words for word in words)\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        return \"Positive\"\n",
    "    elif negative_count > positive_count:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "user_input = input(\"Enter a text: \")\n",
    "sentiment = analyze_sentiment(user_input)\n",
    "\n",
    "print(\"Sentiment:\", sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1f728-d90a-49d5-b7d8-edc10b4181a2",
   "metadata": {},
   "source": [
    "2. Us a regular expression to search through a string and to locate all valid URLs. A valid URL has the form of https://www.domain.ext or http://www.domain.ext where ext needs to be 2 or more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0052a0-fe80-454e-a40e-2ad215196d6d",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 12,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1690635565812,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import re\n\ntext = \"\"\"Our web address is http://www.deitel.com and Pearson's web address is https://www.pearson.com, \nbut https://www.fake.c is not a valid URL\"\"\"\n\nurls = re.findall(r'https?://www\\.\\w+\\.[a-z]{2,}', text)\n\nurls",
    "outputsMetadata": {
     "0": {
      "height": 256,
      "type": "stream"
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.example.com,', 'http://www.example2.net.']\n"
     ]
    }
   ],
   "source": [
    "# Code for Problem 2\n",
    "# Sample text containing URLs\n",
    "text = \"Check out this website: https://www.example.com, and also this one: http://www.example2.net.\"\n",
    "word=text.split()\n",
    "vurl=[]\n",
    "for word in word:\n",
    "    if word.startswith(\"https://www.\") or word.startswith(\"http://www.\"):\n",
    "        vurl.append(word)\n",
    "        \n",
    "print(vurl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ade26-f838-4d75-8ec4-93305fccc728",
   "metadata": {},
   "source": [
    "3. Write code that allows you to enter a student first name, last name and two exam grades (as integers) and save the file as student_grades.csv. The CSV format should be like the following:\n",
    "`firstname, lastname, grade1, grade2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46e5b5d-df23-4405-81ce-238a89318ec2",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 152,
    "lastExecutedAt": 1690798677552,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import csv\n\n# Get student information from user\nfirst_name = 'Eric' # input(\"Enter student's first name: \")\nlast_name = 'Zematis' #input(\"Enter student's last name: \")\ngrade1 = 95 # int(input(\"Enter student's first exam grade: \"))\ngrade2 = 85 # int(input(\"Enter student's second exam grade: \"))\n\n# Create a list with the student information\nstudent_info = [first_name, last_name, grade1, grade2]\n\n# Write the student information to a CSV file\nwith open('student_grades.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['firstname', 'lastname', 'grade1', 'grade2'])  # Write header\n    writer.writerow(student_info)  # Write student information",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter student's first name:  g\n",
      "Enter student's last name:  r\n",
      "Enter first exam grade:  3\n",
      "Enter second exam grade:  4\n"
     ]
    }
   ],
   "source": [
    "# Code for Problem 3\n",
    "import csv\n",
    "first_name = input(\"Enter student's first name: \")\n",
    "last_name = input(\"Enter student's last name: \")\n",
    "grade1 = int(input(\"Enter first exam grade: \"))\n",
    "grade2 = int(input(\"Enter second exam grade: \"))\n",
    "\n",
    "\n",
    "\n",
    "csv_file = \"student_grades_list.csv\"\n",
    "with open(csv_file, \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"firstname\", \"lastname\", \"grade1\", \"grade2\"])  # Write header\n",
    "    csvwriter.writerow([first_name, last_name, grade1, grade2])  # Write the data rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f48192-5e61-42f3-a8e0-8da686e2b8ac",
   "metadata": {},
   "source": [
    "4. Choose your own question! Find a dataset online (as a csv file) and bring it into python as a pandas dataframe and use some of the skills you have developed to do some basic data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a66fd6c9-af16-4dac-8c52-e2dcf713aab5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1689883987982,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Select row 2\nprint(row_2)\n\n# Select column 5\nprint(column_5)\n\n# Select rows 0 and 1\nprint(rows_0_1)\n\n# Select the element in row 1, column 4\nprint(element_1_4)\n\n# Select all elements from rows 1 and 2 that are in columns 0, 2, and 4\nprint(elements_1_2_0_2_4)",
    "outputsMetadata": {
     "0": {
      "height": 270,
      "type": "stream"
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heart</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Person</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cultural</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Inclusion</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Inclusive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Equitable</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Equity</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Accessibility</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sustainability</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sustainability</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Environment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Peer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Care</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Protect</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Protection</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Heart   Count\n",
       "0            Human       5\n",
       "11          Person      11\n",
       "23        Cultural       3\n",
       "30       Inclusion       3\n",
       "31       Inclusive       3\n",
       "34       Equitable       3\n",
       "35          Equity      25\n",
       "36   Accessibility       2\n",
       "37  Sustainability       2\n",
       "38  Sustainability       2\n",
       "41     Environment       3\n",
       "42            Peer       2\n",
       "46            Care       4\n",
       "48         Protect       4\n",
       "49      Protection       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for Problem 4\n",
    "import pandas as pd\n",
    "#aap is a csv on how many postive words(from a word list) were found in advanced autoparts 10k\n",
    "#was pulled from my github from my previous internship\n",
    "#want to see which word exist multiple times\n",
    "#readcsv\n",
    "ogcsv=pd.read_csv('aap.csv')\n",
    "\n",
    "#select relevant columns and data cleaning\n",
    "dd=ogcsv.iloc[:, [0, 2]]\n",
    "df = dd.drop(dd.index[-2:])\n",
    "df.rename(columns={'0': 'Count'}, inplace=True)\n",
    "df['Count'] = df['Count'].astype(int)\n",
    "#display(df)\n",
    "#sort and displaynewdf with all correct values\n",
    "new_df = df[df['Count'] > 1]\n",
    "\n",
    "display(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2579f2-1f08-40aa-9087-f9100c68a9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58f970-613e-4708-bc50-c1bd6f52bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
